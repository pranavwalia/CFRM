{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In a previous exercise we solved rock paper scissors using counterfactual regret minimization. Now, we will apply the principles learned from RPS to solve a more intriguing exercise.\n",
    "\n",
    "We will be solving a sub-game of the more general [Colonel Blotto](https://en.wikipedia.org/wiki/Blotto_game) resource allocation problem. In this game, two millitary generals must allocate S soldiers across N possible battlefields. Allocating more soldiers to a battlefield than one's opponent results in a conquest. Allocating an equal number of soldiers results in a tie. The player with the most conquests wins the round."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "This problem was originally posed as an exercise in [Introduction To Counterfactual Regret Minimization, Todd W. Neller and Lanctot](http://modelai.gettysburg.edu/2013/cfr/cfr.pdf). I could not find an available solution to this problem online so I took it upon myself to make one.\n",
    "\n",
    "## Colonel Blotto Toy Game (S, N) = (5, 3)\n",
    "Write a program that solves the Colonel Blotto problem for S = 5 soldiers and N = 3 battlefields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed vs Pure Strategy\n",
    "In the context of this game, a 'pure' strategy is a single possible allocation of soldiers eg. (3,1,1). A mixed strategy is a mixed allocation of soldiers. Example: choosing (3,1,1) 30% of the time and (5,00) 70% of the time. We will begin by implementing a function that can generate all possible pure strategies. \n",
    "\n",
    "A valid allocation can be modeled as a linear equation consisting of N variables where the sum of those variables are S\n",
    "$$\n",
    "\\sum_{i = 1}^{N} X_{i} = S\n",
    "$$\n",
    "In the case of this game, N = 3 and S = 5\n",
    "$$\n",
    "\\sum_{i = 1}^{3} X_{i} = 5\n",
    "$$\n",
    "Where $$X_{i}$$ is an integer and $$0 \\leq X_{i} \\leq 5$$\n",
    "\n",
    "Knowing this, we will write a function that generates all possible solutions to the equation under these constraints. Each solution will be a possible pure strategy.\n",
    "\n",
    "## Implementation\n",
    "Note: We will be implementing this in a functional style rather than an object oriented one. This format works better when explaining math in conjunction with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Strategies\n",
    "Since our problem only contains 3 battle-fields, we can straightforwardly generate all solutions to the equation using 2 nested loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate all pure strategies for n = 3, S = 5\n",
    "def generateStrategies():\n",
    "    s = 5\n",
    "    strats = []\n",
    "    for x1 in range(s + 1):\n",
    "        current_strat = []\n",
    "        for x2 in range((s + 1) - x1):\n",
    "            for x3 in range((s + 1) - (x1 + x2)):\n",
    "                if (x1 + x2 + x3) == s:\n",
    "                    current_strat = [x1,x2,x3]\n",
    "                    strats.append(current_strat)\n",
    "    return strats        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the function will generate 21 possible unique allocations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 5],\n",
       " [0, 1, 4],\n",
       " [0, 2, 3],\n",
       " [0, 3, 2],\n",
       " [0, 4, 1],\n",
       " [0, 5, 0],\n",
       " [1, 0, 4],\n",
       " [1, 1, 3],\n",
       " [1, 2, 2],\n",
       " [1, 3, 1],\n",
       " [1, 4, 0],\n",
       " [2, 0, 3],\n",
       " [2, 1, 2],\n",
       " [2, 2, 1],\n",
       " [2, 3, 0],\n",
       " [3, 0, 2],\n",
       " [3, 1, 1],\n",
       " [3, 2, 0],\n",
       " [4, 0, 1],\n",
       " [4, 1, 0],\n",
       " [5, 0, 0]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateStrategies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Utility\n",
    "Computing utility for a round of Colonel Blotto is as simple as counting how many battle-fields are won in a single round. The arguments we pass to the function will be lists of length 3 representing strategy profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute utility for player 1\n",
    "#Assume p1 and p2 are \n",
    "def getUtility(p1,p2):\n",
    "    u = 0\n",
    "    for i in range(len(p1)):\n",
    "        if p1[i] > p2[i]:\n",
    "            u+=1\n",
    "    return u"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Action According To Current Strategy\n",
    "Next, we will want to create a function that randomly allocates soldiers to battle fields based on a given strategy profile. A strategy profile can be represented as a list of 21 real numbers $$X$$\n",
    "where $$ 0 \\leq X_{i}\\leq 1$$\n",
    "Each element of the list represents a frequency at which a corresponding allocation is chosen. As such, the sum of all the elements in the list must be equal to 1.\n",
    "$$\n",
    "\\sum_{i = 1}^{21}X_{i} = 1\n",
    "$$\n",
    "\n",
    "Let us first make a function that generates a default strategy profile where each action is equally weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function generates a default strategy where each action profile has equal weighting\n",
    "def defaultStrat():\n",
    "    actionProfiles = generateStrategies()\n",
    "    strat = []\n",
    "    for i in range(len(actionProfiles)):\n",
    "        strat.append(1/len(actionProfiles))\n",
    "    return strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultStrat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that randomly chooses an action profile given a strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[List] -> [X1,X2,X3]\n",
    "def getAction(strategy):\n",
    "    rand = random.random()\n",
    "    actions = generateStrategies()\n",
    "    leftSum = 0\n",
    "    rightSum = 0\n",
    "    for i in range(len(strategy)):\n",
    "        rightSum+=strategy[i]\n",
    "        if rand > leftSum and rand <= rightSum:\n",
    "            return actions[i]\n",
    "        else:\n",
    "            leftSum+=strategy[i]\n",
    "    return actions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 3]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAction(defaultStrat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Regret Matched Strategy\n",
    "We will now write a function that computes a regret matched strategy based on a regret sum and a strategy sum. The regret sum is a list of 21 elements where each element represents the expected value of a particular decision in a particular round of the game. The strategySum is the current accumulated sum of all normalized strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Returns the adjusted strategy after an iteration\n",
    "def getStrategy(regretSum,strategySum):\n",
    "    actions = 21\n",
    "    normalizingSum = 0\n",
    "    strategy = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "    #Normalizingsum is the sum of positive regrets. \n",
    "    #This ensures do not 'over-adjust' our strategy\n",
    "    for i in range(0,actions):\n",
    "        if regretSum[i] > 0:\n",
    "            strategy[i] = regretSum[i]\n",
    "        else:\n",
    "            strategy[i] = 0\n",
    "        normalizingSum += strategy[i]\n",
    "    ##This loop normalizes our updated strategy\n",
    "    for i in range(0,actions):\n",
    "        if normalizingSum > 0:\n",
    "            strategy[i] = strategy[i]/normalizingSum\n",
    "        else:\n",
    "            #Default to 33%\n",
    "            strategy[i] = 1.0 / actions\n",
    "        strategySum[i] += strategy[i]\n",
    "    return (strategy,strategySum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Algorithm\n",
    "We will write a training algorithm that allows both agents to converge to a game theory optimal solution of [Nash Equilibria](https://en.wikipedia.org/wiki/Nash_equilibrium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations,regretSum,oppStrategy):\n",
    "    actionUtility = [0,0,0]\n",
    "    strategySum = [0,0,0]\n",
    "    actions = 3\n",
    "    for i in range(0,iterations):\n",
    "        ##Retrieve Actions\n",
    "        t = getStrategy(regretSum,strategySum)\n",
    "        strategy = t[0]\n",
    "        strategySum = t[1]\n",
    "        #print(strategy)\n",
    "        myaction = getAction(strategy)\n",
    "        #Define an arbitrary opponent strategy from which to adjust\n",
    "        otherAction = getAction(oppStrategy)   \n",
    "        #Opponent Chooses scissors\n",
    "        if otherAction == actions - 1:\n",
    "            #Utility(Rock) = 1\n",
    "            actionUtility[0] = 1\n",
    "            #Utility(Paper) = -1\n",
    "            actionUtility[1] = -1\n",
    "        #Opponent Chooses Rock\n",
    "        elif otherAction == 0:\n",
    "            #Utility(Scissors) = -1\n",
    "            actionUtility[actions - 1] = -1\n",
    "            #Utility(Paper) = 1\n",
    "            actionUtility[1] = 1\n",
    "        #Opopnent Chooses Paper\n",
    "        else:\n",
    "            #Utility(Rock) = -1\n",
    "            actionUtility[0] = -1\n",
    "            #Utility(Scissors) = 1\n",
    "            actionUtility[2] = 1\n",
    "            \n",
    "        #Add the regrets from this decision\n",
    "        for i in range(0,actions):\n",
    "            regretSum[i] += actionUtility[i] - actionUtility[myaction]\n",
    "    return strategySum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
