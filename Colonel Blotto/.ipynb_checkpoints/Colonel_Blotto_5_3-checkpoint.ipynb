{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is The Colonel Blotto Problem?\n",
    "\n",
    "We will be solving a sub-game of the more general [Colonel Blotto](https://en.wikipedia.org/wiki/Blotto_game) resource allocation problem. In this game, two millitary generals must allocate S soldiers across N possible battlefields. Allocating more soldiers to a battlefield than one's opponent results in a conquest. Allocating an equal number of soldiers results in a tie. The player with the most conquests wins the round.\n",
    "\n",
    "All code is available on my [CFRM repository](https://github.com/pranavwalia/CFRM/tree/master/Colonel%20Blotto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Colonel Blotto Toy Game (S, N) = (5, 3)\n",
    "Write a program that solves the Colonel Blotto problem for S = 5 soldiers and N = 3 battlefields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed vs Pure Strategy\n",
    "In the context of this game, a 'pure' strategy is a single possible allocation of soldiers eg. (3,1,1). A mixed strategy is a mixed allocation of soldiers. Example: choosing (3,1,1) 30% of the time and (5,00) 70% of the time. We will begin by implementing a function that can generate all possible pure strategies. \n",
    "\n",
    "A valid allocation can be modeled as a linear equation consisting of N variables where the sum of those variables are S\n",
    "$$\n",
    "\\sum_{i = 1}^{N} X_{i} = S\n",
    "$$\n",
    "In the case of this game, N = 3 and S = 5\n",
    "$$\n",
    "\\sum_{i = 1}^{3} X_{i} = 5\n",
    "$$\n",
    "Where $$X_{i}$$ is an integer and $$0 \\leq X_{i} \\leq 5$$\n",
    "\n",
    "Knowing this, we will write a function that generates all possible solutions to the equation under these constraints. Each solution will be a possible pure strategy.\n",
    "\n",
    "## Implementation\n",
    "Note: We will be implementing this in a functional style rather than an object oriented one. This format works better when explaining math in conjunction with code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Strategies\n",
    "Since our problem only contains 3 battle-fields, we can straightforwardly generate all solutions to the equation using 2 nested loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate all pure strategies for n = 3, S = 5\n",
    "def generateStrategies():\n",
    "    s = 5\n",
    "    strats = []\n",
    "    for x1 in range(s + 1):\n",
    "        current_strat = []\n",
    "        for x2 in range((s + 1) - x1):\n",
    "            for x3 in range((s + 1) - (x1 + x2)):\n",
    "                if (x1 + x2 + x3) == s:\n",
    "                    current_strat = [x1,x2,x3]\n",
    "                    strats.append(current_strat)\n",
    "    return strats        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the function will generate 21 possible unique allocations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0, 5],\n",
       " [0, 1, 4],\n",
       " [0, 2, 3],\n",
       " [0, 3, 2],\n",
       " [0, 4, 1],\n",
       " [0, 5, 0],\n",
       " [1, 0, 4],\n",
       " [1, 1, 3],\n",
       " [1, 2, 2],\n",
       " [1, 3, 1],\n",
       " [1, 4, 0],\n",
       " [2, 0, 3],\n",
       " [2, 1, 2],\n",
       " [2, 2, 1],\n",
       " [2, 3, 0],\n",
       " [3, 0, 2],\n",
       " [3, 1, 1],\n",
       " [3, 2, 0],\n",
       " [4, 0, 1],\n",
       " [4, 1, 0],\n",
       " [5, 0, 0]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generateStrategies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Utility\n",
    "Computing utility for a round of Colonel Blotto is as simple as counting how many battle-fields are won in a single round. The arguments we pass to the function will be lists of length 3 representing strategy profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute utility for player 1\n",
    "#Assume p1 and p2 are \n",
    "def getUtility(p1,p2):\n",
    "    u = 0\n",
    "    for i in range(len(p1)):\n",
    "        if p1[i] > p2[i]:\n",
    "            u+=1\n",
    "    return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getUtility([2,3,1],[3,1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Action According To Current Strategy\n",
    "Next, we will want to create a function that randomly allocates soldiers to battle fields based on a given strategy profile. A strategy profile can be represented as a list of 21 real numbers $$X$$\n",
    "where $$ 0 \\leq X_{i}\\leq 1$$\n",
    "Each element of the list represents a frequency at which a corresponding allocation is chosen. As such, the sum of all the elements in the list must be equal to 1.\n",
    "$$\n",
    "\\sum_{i = 1}^{21}X_{i} = 1\n",
    "$$\n",
    "\n",
    "Let us first make a function that generates a default strategy profile where each action is equally weighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function generates a default strategy where each action profile has equal weighting\n",
    "def defaultStrat():\n",
    "    actionProfiles = generateStrategies()\n",
    "    strat = []\n",
    "    for i in range(len(actionProfiles)):\n",
    "        strat.append(1/len(actionProfiles))\n",
    "    return strat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616,\n",
       " 0.047619047619047616]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defaultStrat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will write a function that randomly chooses an action profile given a strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[List] -> [X1,X2,X3]\n",
    "def getAction(strategy):\n",
    "    rand = random.random()\n",
    "    actions = generateStrategies()\n",
    "    leftSum = 0\n",
    "    rightSum = 0\n",
    "    for i in range(len(strategy)):\n",
    "        rightSum+=strategy[i]\n",
    "        if rand > leftSum and rand <= rightSum:\n",
    "            return actions[i]\n",
    "        else:\n",
    "            leftSum+=strategy[i]\n",
    "    return actions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4, 1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getAction(defaultStrat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility of One Strategy vs Another\n",
    "Additionally, we want a way of measuring the utility of one strategy vs another. This will come in handy when evaluating the results of our algorithm.\n",
    "\n",
    "* Let $A$ represent the set of all action profiles where $A_{1},A_{2}..A_{21}$ are the 21 possible action profiles in the game \n",
    "\n",
    "* Let $G$ be the strategy profile (list of frequencies for player1's action selection\n",
    "\n",
    "* Let $R$ be the strategy profile (list of frequencies for player1's action selection\n",
    "\n",
    "* Let $\\alpha(A_{x},A_{i})$ be the utility of action $A_{x}$ against action $A_{i}$\n",
    "\n",
    "* Let $U(A_{x},R)$ be the utility function returning the average utility of playing action profile $A_{x}$ against strategy profile $S$\n",
    "\n",
    "$$\n",
    "U(A_{1},R) = \\sum_{i = 1}^{21}\\alpha(A_{x},A_{i})R_{i}\n",
    "$$\n",
    "\n",
    "* Let $U_{A}(G,R)$ be the average utility of strategy $G$ this is calculated by multiplying the utility of every action in A by the frequency it is chosen in G.\n",
    "\n",
    "$$\n",
    "U_{A}(G,R) = \\sum_{i = 1}^{21} U(A_{i},R)G_{i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utilityAverage(g,r):\n",
    "    actions = generateStrategies()\n",
    "    actionUtilities = [0] * 21\n",
    "    for i in range(len(actions)):\n",
    "        u = 0\n",
    "        for j in range(len(actions)):\n",
    "            u+=((getUtility(actions[i],actions[j]) * r[i]))  \n",
    "        actionUtilities[i] = u * g[i]\n",
    "    \n",
    "    return sum(actionUtilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Regret Matched Strategy\n",
    "We will now write a function that computes a regret matched strategy based on a regret sum and a strategy sum. The regret sum is a list of 21 elements where each element represents the regret differential of each action in a particular round of the game. The strategySum is the current accumulated sum of all normalized strategies.\n",
    "\n",
    "Our function will return a tuple of the most recent strategy and the sum of all previous strategies in the format\n",
    "\n",
    "$$\n",
    "(strategy,strategySum)\n",
    "$$\n",
    "\n",
    "#### Regret Sum\n",
    "The regretSum is calculated by taking the difference of the expected value of each alternate action and the action that was used in a particular round. Positive regrets are ones where an agent could have gained utility by choosing an alternate action profile. Negative regrets are actions that would have been worse than the choosen strategy.\n",
    "\n",
    "#### Strategy Sum\n",
    "The strategy sum is the sum of all previous normalized regret matched strategies.\n",
    "\n",
    "#### Why we normalize\n",
    "The regret of each decision must be matched in terms of the total regret generated by choosing a particular action in a round rather than the total absolute regret. This ensures that strategic adjustments are not skewed by variance resulting in an incorrect average strategy profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Returns the adjusted strategy after an iteration\n",
    "def getStrategy(regretSum,strategySum):\n",
    "    actions = 21\n",
    "    normalizingSum = 0\n",
    "    strategy = [0] * 21\n",
    "    #Normalizingsum is the sum of positive regrets. \n",
    "    #This ensures do not 'over-adjust' our strategy\n",
    "    for i in range(0,actions):\n",
    "        if regretSum[i] > 0:\n",
    "            strategy[i] = regretSum[i]\n",
    "        else:\n",
    "            strategy[i] = 0\n",
    "        normalizingSum += strategy[i]\n",
    "    ##This loop normalizes our updated strategy\n",
    "    for i in range(0,actions):\n",
    "        if normalizingSum > 0:\n",
    "            strategy[i] = strategy[i]/normalizingSum\n",
    "        else:\n",
    "            #Default to 33%\n",
    "            strategy[i] = 1.0 / actions\n",
    "        strategySum[i] += strategy[i]\n",
    "    return (strategy,strategySum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Algorithm For Maximally Exploitative Strategy\n",
    "We will write a training algorithm that calculates a maximally exploitative strategy for player1 against a static strategy from player 2. The function will simulate a set number of iterations. At each iteration, it will retrieve a regret-matched strategy for player1. Using this strategy, it will select an action. Afterwards, the static action profile will be used to retrieve an action for player 2. Finally, regrets will be calculated and player1's strategy will be adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iterations,regretSum,oppStrategy):\n",
    "    actionUtility = [0] * 21\n",
    "    strategySum = [0] * 21\n",
    "    actions = 21\n",
    "    for i in range(0,iterations):\n",
    "        ##Retrieve Actions\n",
    "        t = getStrategy(regretSum,strategySum)\n",
    "        strategy = t[0]\n",
    "        strategySum = t[1]\n",
    "        myAction = getAction(strategy)\n",
    "        oppAction = getAction(oppStrategy)   \n",
    "        actionList = generateStrategies()\n",
    "        \n",
    "        for i in range(len(actionList)):\n",
    "            actionUtility[i] = getUtility(actionList[i],oppAction)\n",
    "            \n",
    "        #Add the regrets from this decision\n",
    "        for i in range(actions):\n",
    "            regretSum[i] += actionUtility[i] - getUtility(myAction,oppAction)\n",
    "    return strategySum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAverageStrategy(iterations,oppStrategy):\n",
    "    regretSum = [0] * 21\n",
    "    oppStrategy = defaultStrat()\n",
    "    iterations = 1000000\n",
    "    strategySum = train(iterations,regretSum,oppStrategy)\n",
    "    normalizingSum = 0\n",
    "    actions = 21\n",
    "    avgStrategy = [0] * 21\n",
    "    for i in range(0,actions):\n",
    "        normalizingSum += strategySum[i]\n",
    "    for i in range(0,actions):\n",
    "        if normalizingSum > 0:\n",
    "            avgStrategy[i] = strategySum[i] / normalizingSum\n",
    "        else:\n",
    "            avgStrategy[i] = 1.0 / actions\n",
    "    return avgStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1.9047619047617735e-07, 3.9047619047616363e-07, 3.27328150779367e-05, 2.4493122009567682e-05, 1.9047619047617735e-07, 1.9047619047617735e-07, 1.9047619047617735e-07, 1.9047619047617735e-07, 0.6157282010685945, 1.9047619047617735e-07, 1.9047619047617735e-07, 1.9047619047617735e-07, 0.09827837823853097, 0.285915035607526, 3.346800421800192e-06, 1.9047619047617735e-07, 1.9047619047617735e-07, 1.4945681172112038e-05, 1.9047619047617735e-07, 1.9047619047617735e-07, 1.9047619047617735e-07]\n"
     ]
    }
   ],
   "source": [
    "oppStrategy = defaultStrat()\n",
    "weirdStrategy = [1] + [0] * 20\n",
    "print(weirdStrategy)\n",
    "maxExploit = getAverageStrategy(1000000,weirdStrategy)\n",
    "print(maxExploit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.469446951953614e-18\n",
      "0.2856988273306818\n"
     ]
    }
   ],
   "source": [
    "print(utilityAverage(defaultStrat(),defaultStrat()))\n",
    "print(utilityAverage(defaultStrat(),maxExploit))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2856988273306818"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utilityAverage(defaultStrat(),maxExploit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting plotly.express\n",
      "  Downloading plotly_express-0.4.1-py2.py3-none-any.whl (2.9 kB)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/pranav/.local/lib/python3.8/site-packages (from plotly.express) (1.19.2)\n",
      "Collecting plotly>=4.1.0\n",
      "  Downloading plotly-4.14.1-py2.py3-none-any.whl (13.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.2 MB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /home/pranav/anaconda3/lib/python3.8/site-packages (from plotly.express) (0.12.0)\n",
      "Requirement already satisfied: scipy>=0.18 in /home/pranav/anaconda3/lib/python3.8/site-packages (from plotly.express) (1.5.2)\n",
      "Requirement already satisfied: pandas>=0.20.0 in /home/pranav/.local/lib/python3.8/site-packages (from plotly.express) (1.1.3)\n",
      "Requirement already satisfied: patsy>=0.5 in /home/pranav/anaconda3/lib/python3.8/site-packages (from plotly.express) (0.5.1)\n",
      "Collecting retrying>=1.3.3\n",
      "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
      "Requirement already satisfied: six in /home/pranav/anaconda3/lib/python3.8/site-packages (from plotly>=4.1.0->plotly.express) (1.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/pranav/anaconda3/lib/python3.8/site-packages (from pandas>=0.20.0->plotly.express) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/pranav/anaconda3/lib/python3.8/site-packages (from pandas>=0.20.0->plotly.express) (2020.1)\n",
      "Building wheels for collected packages: retrying\n",
      "  Building wheel for retrying (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11429 sha256=ca81b94b6a1dfbcab40791868715519c09db8a34a478c5571885b3df64abac4b\n",
      "  Stored in directory: /home/pranav/.cache/pip/wheels/c4/a7/48/0a434133f6d56e878ca511c0e6c38326907c0792f67b476e56\n",
      "Successfully built retrying\n",
      "Installing collected packages: retrying, plotly, plotly.express\n",
      "Successfully installed plotly-4.14.1 plotly.express retrying-1.3.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install plotly.express\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources and Further Reading\n",
    "This problem was originally posed as an exercise in [Introduction To Counterfactual Regret Minimization, Todd W. Neller and Lanctot](http://modelai.gettysburg.edu/2013/cfr/cfr.pdf). I could not find an available solution to this problem online so I took it upon myself to make one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
